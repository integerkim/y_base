<!DOCTYPE html>
<!--
	Delex by TEMPLATE STOCK
	templatestock.co @templatestock
	Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->

<html lang="en">
<head>
  <!-- Meta Tags -->
  <meta charset="utf-8"/>

  <!-- Site Title-->
<!--  <title>Delex HTML5 Free Responsive Template | Template Stock</title>-->
  <title>2021 Y-BASE AI Symposium</title>

  <!-- Mobile Specific Metas-->
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

  <!-- Google-fonts -->
  <link href='http://fonts.googleapis.com/css?family=Signika+Negative:300,400,600,700' rel='stylesheet' type='text/css'>
  <link href='http://fonts.googleapis.com/css?family=Kameron:400,700' rel='stylesheet' type='text/css'>
  
  <!-- Bootstrap -->
  <link rel="stylesheet" href="css/bootstrap.min.css"/>
  <!-- Fonts-style -->
  <link rel="stylesheet" href="css/styles.css"/>
  <!-- Fonts-style -->
  <link rel="stylesheet" href="css/font-awesome.min.css"/>
  <!-- Modal-Effect -->
  <link href="css/component.css" rel="stylesheet">
  <!-- owl-carousel -->
  <link href="css/owl.carousel.css" rel="stylesheet" type="text/css" media="screen">
  <link href="css/owl.theme.css" rel="stylesheet" type="text/css" media="screen">
  <!-- Template Styles-->
  <link rel="stylesheet" href="css/style.css"/>
  <!-- Template Color-->
  <link rel="stylesheet" type="text/css" href="css/green.css" media="screen" id="color-opt" />



</head>

<body data-spy="scroll" data-offset="80">

  <!-- Preloader -->
  <div class="animationload">
    <div class="loader">
        Please Wait....
    </div>
  </div> 
  <!-- End Preloader -->


  <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
    <div class="container">
      <!-- Brand and toggle get grouped for better mobile display -->
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="#">2021 Y-BASE AI SYMPOSIUM</a>
      </div>

      <!-- Collect the nav links, forms, and other content for toggling -->
      <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
        <ul class="nav navbar-nav navbar-right">
          <li><a href="#home">Home</a></li>
<!--          <li><a href="#services">Services</a></li>-->
          <li><a href="#organizers">Keynote Speaker</a></li>
<!--          <li><a href="#twitter_tweet">Testimonials</a></li>-->
          <li><a href="#abstract">Abstract</a></li>
          <li><a href="#tentative">Tentative Schedule</a></li>
          <li><a href="#ats">About The Speaker</a></li>
        </ul>
      </div><!-- /.navbar-collapse -->
    </div><!-- /.container -->
  </nav>

    <!-- /HOME -->
    <section class="main-home" id="home">
      <div class="home-page-photo"></div> <!-- Background image -->
      <div class="home__header-content">
        <div id="main-home-carousel" class="owl-carousel">
          <div>
            <h1 class="intro-title"><b>What You Need to Know About the METAVERSE: <br/>Quality of Experience (QoE)</b><h1>
            <p class="intro-text">Metaverse is a concept that can be described as a combination of physical and virtual reality. Users can experience a virtual space <br/>
              where the physical world links with the virtual world. They can share experiences and interact in real-time within virtual scenarios.</p>
            <a class="btn btn-custom" href="https://zoom.us/">Get started</a>
          </div><!--slide item like paragraph-->
        </div>
      </div>
    </section>
    <!-- /End HOME -->

    <!-- / SERVICES -->
    <section id="organizers">
      <div class="container">
        <div class="row">
          <div class="col-md-12">
            <h3 class="title text-center">Keynote Speaker</h3>
            <div class="titleHR"><span></span></div>
          </div>
        </div>
        
        <div class="row">
          <div class="col-sm-3"> <!-- Service-item -->
            <div class="text-center services-item">
              <div class="col-wrapper">
                <div class="icon-border">
                  <a href="http://live.ece.utexas.edu/" class="instructorphoto"><img src="images/Alan_Conrad_Bovik.png" alt="" /></a>
<!--                  <i class="icon-design-graphic-tablet-streamline-tablet color-l-orange"></i> -->
                </div>
                <h5><a href="#ats">Alan Conrad Bovik</a></h5>
                <p>The University of Texas at Austin.</p>
              </div>
            </div>
          </div>
          <div class="col-sm-3"> <!-- Service-item -->
            <div class="text-center services-item">
              <div class="col-wrapper">
                <div class="icon-border">
                  <a href="http://insight.yonsei.ac.kr/gnuboard/" class="instructorphoto"><img src="images/un.jpg" alt="" /></a>
<!--                  <i class="icon-design-graphic-tablet-streamline-tablet color-l-orange"></i> -->
                </div>
                <h5><a href="#ats">Keynote Speaker</a></h5>
                <p>Nulla vitae libero pharetra augue. Etiam porta malesuada magna mollis euismod consectetur sem urdom tempus porttitor.</p>
              </div>
            </div>
          </div>   
          <div class="col-sm-3"> <!-- Service-item -->
            <div class="text-center services-item">
              <div class="col-wrapper">
                <div class="icon-border">
                  <a href="http://insight.yonsei.ac.kr/gnuboard/" class="instructorphoto"><img src="images/un.jpg" alt="" /></a>
<!--                  <i class="icon-design-graphic-tablet-streamline-tablet color-l-orange"></i> -->
                </div>
                <h5><a href="#ats">Keynote Speaker</a></h5>
                <p>Nulla vitae libero pharetra augue. Etiam porta malesuada magna mollis euismod consectetur sem urdom tempus porttitor.</p>
              </div>
            </div>
          </div> 
          <div class="col-sm-3"> <!-- Service-item -->
            <div class="text-center services-item">
              <div class="col-wrapper">
                <div class="icon-border">
                  <a href="http://insight.yonsei.ac.kr/gnuboard/" class="instructorphoto"><img src="images/sanghoon.png" alt="" /></a>
<!--                  <i class="icon-design-graphic-tablet-streamline-tablet color-l-orange"></i> -->
                </div>
                <h5><a href="#ats">Sanghoon Lee</a></h5>
                <p>Yonsei University, Korea.</p>
              </div>
            </div>
          </div> 
        </div> <!--/.row -->
      </div> <!--/.container -->
    </section>
    <!-- / End services-->


    <!-- TWITTER TWEET -->
    <section class="abstract parallax" id="abstract" data-stellar-background-ratio="0.5">
      <div class="container">
        <div class="row">
          <div class="col-md-12">
            <h3 class="title-white text-center">Abstract</h3>
            <div class="titleHR"><span></span></div>
          </div>
        </div>
        <div class="row">
          <h4>Today, the metaverse is a shared virtual space where people are represented by digital avatars (think Ready Player One). The virtual world constantly grows and evolves based on the decisions and actions of the society within it. Eventually, people will be able to enter the metaverse, completely virtual (i.e. with virtual reality) or interact with parts of it in their physical space with the help of augmented and mixed reality.<br/><br/>
          The metaverse can be said to be a revolutionary change by merging the 2D natural scenes with 3D computer graphic scenes. First, there is a difference between the existing PC and mobile-based internet era and the metaverse era in terms of convenience, interaction method, and screen/space expandability. Specifically, it is evolving from a 2D web screen to a 3D spatial web where the limitations of the screen have disappeared. The second is the technical aspect. The technology that implements the metaverse is a composite of General Purpose Technology, XR+DNA (eXtended Reality + Data, Network, and Artificial intelligence). These core technologies aim to implement virtual space as it really is, to perceive it as a person perceives it, and to break down reality and virtual barriers. However, making fully interactive 3D metaverse with high-quality video has never been easier.<br/><br/> 
          Therby, it is necessary to assess the quality of experience (QoE) perceived by users adaptive to those future multimedia systems. In this context, this tutorial aims at bridging METAVERSE media with QoE assessment. Through evaluating the QoE of media experiences, we aim to quantify the usersâ€™ perceived quality of a system or service that affects their experience. Moreover, this symposium does not only focus on QoE but aims to understand and quantify the overall user experience, by taking into account personal and situational factors. Finally, we will discuss how to evaluate the QoE for next-generation multimedia from the human cognitive perspective, present the latest articles aligned with the recent industrial trends, contents acquisition, and quality assessment, and have technical exchanges.</h4>
        </div>
      </div> <!-- container -->
    </section>
    <!-- End TWITTER TWEET -->

    <!-- CONTACT -->
    <section id="tentative">
      <div class="container">
        <div class="row">
          <div class="col-md-12">
            <h3 class="title text-center">Tentative Schedule</h3>
            <h4 class="title text-center"><a href="https://zoom.us/">October 00, 2021</a></h4>
            <div class="titleHR"><span></span></div>
          </div>
        </div>
        <div class="row services-item">
          <p><span class="announce_date"><b>08:40-08:50 am</b></span> - <b>Opening remarks.</b> <a href="https://jw09191.github.io"><em>Seounghwan Suh</em></a> </p>
          <p><span class="announce_date"><b>08:50-09:00 am</b></span> - <b>Congratulatory remarks.</b> <a href="https://jw09191.github.io/"><em>Hyesook Lim</em></a> </p>
          <p class="subtitle"><span class="announce_date"><b>09:00-09:40 am</b></span> - <b>Visual perception quantification and ultra-precision technique for the creation of hyper-realistic 3D human entity.</b> <a href="#ats"><em>Sanghoon Lee</em></a>. 
          </br> In this symposium, we present a technology that generates a hyper-realistic redered image of a target person viewed from a various direction with a different motion by referring to an intermediate 3D representation of the human which we call the 3D human entity. Towards this goal, we first construct a multi-camera studio to obtain accurate and sufficient 3D human data to analyze the natural and realistic statistics of humans. Next, we present metrics which quantify the degree of reality perceived by humans based on the human visual perception. Using the quantified sense of reality, we finally develop an ultra-precision technology which generates hyper-realistic images of a person in various viewpoints and motions from a 3D human entity reconstrcted from an image. [<a href="">slides</a>] [<a href="https://youtube.com">recorded video</a>]</p>
          <p class="subtitle"><span class="announce_date"><b>09:40-10:20 am</b></span> - <b>Deep learning for cardiovascular imaging applications.</b> <a href="https://jw09191.github.io/"> <em>Presenter2</em></a>. 
          </br> Clinical practice has been revolutionized through advancements in non-invasive imaging modalities. In particular, the field of cardiovascular medicine has witnessed widespread adoption of computed tomography (CT), magnetic resonance imaging (MRI), echocardiography, and nuclear perfusion imaging for day-to-day clinical practice. The incorporation of an imaging approach in the diagnostic and prognostic process has allowed for the institution of precise, patient-oriented and disease-targeted cardiovascular therapies. Nevertheless, manual review and interpretation of increasing volumes of cardiovascular imaging studies have been associated with an inefficient workflow, significant time requirements as well as significant intra- and inter-reader variability. The aim of this session is to share the general methods by which deep learning models have been used for segmentation and classification tasks within the realm of cardiovascular imaging, with an emphasis on the advantages of incorporating artificial intelligence and deep learning within a clinical workflow. [<a href="">slides</a>] [<a href="https://youtu.be/b_Z8B9tSyJg">recorded video</a>]</p>
          <p class="subtitle"><span class="announce_date"><b>10:20-11:00 am</b></span> - <b>Clinical context for medical imaging deep learning models: model fusion techniques to combine medical imaging.</b> <a href="https://jw09191.github.io/"> <em>Presenter3</em></a>. 
          </br> Advancements in computer vision and deep learning techniques carry the potential to make significant contributions to healthcare, particularly in fields that utilize medical imaging for diagnosis, prognosis, and treatment decisions. The current state of the art deep learning models for automated diagnosis and outcome prediction using medical imaging tend not to consider patient electronic medical records and clinical variables. Pertinent and accurate information regarding the current symptoms and past medical history enables physicians to interpret imaging findings in the appropriate clinical context, leading to higher diagnostic accuracy, better clinical predictions, and ideally a better outcome for the patient. Deep learning models that use images without clinical context will ultimately be limited, just as physicians cannot be effective without the knowledge of the patient's medical records. In this session, we describe different fusion techniques applied to combine medical imaging with other clinical data, and systematically review literature in this field. We will also present current knowledge and summarize the key insights that researchers can use to make advancements in deep learning for medicine. [<a href="">slides</a>] [<a href="https://youtube.com">recorded video</a>]</p>
          <p class="subtitle"><span class="announce_date"><b>11:00-11:50 am</b></span> - <b>Panel discussion.</b> <a href="#ats"> <em>Alan Conrad Bovik</em></a>. 
          </br> This event would be a symposium since we have keynote speakers and a panel discussion. During the discussion, we get questions from the audience over the chatbox.</p>
        </div>
      </div> <!-- container -->
    </section>
    <!-- End CONTACT -->

        <!-- CONTACT -->
    <section class="abstract" id="ats">
      <div class="container">
        <div class="row">
          <div class="col-md-12">
            <h3 class="title text-center">About The Speaker</h3>
            <div class="titleHR"><span></span></div>
          </div>
        </div>
        <div class="row services-item">
          <p><a href="http://live.ece.utexas.edu/"><b>Alan Conrad Bovik</b></a> 
          </br>holds the Cockrell Family Endowed Regents Chair in Engineering at The University of Texas at Austin, where he is Director of the Laboratory for Image and Video Engineering (LIVE). He is a faculty member in the Department of Electrical and Computer Engineering, the Wireless Networking and Communication Group (WNCG), and the Institute for Neuroscience. His research interests include digital television, digital photography, visual perception, social media, and image and video processing. He has published over 900 technical articles in these areas and holds several U.S. patents. His publications have been cited more than 120,000 times in the literature, his H-index is above 120, and he is listed as a Highly-Cited Researcher by The Web of Science Group. His several books include the The Handbook of Image and Video Processing (Academic Press, 2000, 2005), Modern Image Quality Assessment (2006), and the companion volumes The Essential Guides to Image and Video Processing (Academic Press, 2009).</p>
          <p><a href="https://jw09191.github.io"><b>Speaker1</b></a> 
          </br>Ph.D., Assistant Professor in the Department of Biomedical Informatics and Radiology at Emory University School of Medicine. Her core expertise is unstructured data analysis with deep learning and machine representation of image semantics. She published several manuscripts proposing novel methods for radiology text mining in top-tier journals and conferences. </p>
          <p><a href="https://jw09191.github.io"><b>Speaker2</b></a> 
          </br>Ph.D., Assistant Professor in the Department of Biomedical Informatics and Radiology at Emory University School of Medicine. Her core expertise is unstructured data analysis with deep learning and machine representation of image semantics. She published several manuscripts proposing novel methods for radiology text mining in top-tier journals and conferences. </p>
          <p><a href="http://insight.yonsei.ac.kr/gnuboard/"><b>Sanghoon Lee</b></a> </br> joined the faculty of the Department of Electrical and Electronics Engineering, Yonsei University, Seoul, Korea, where he is a full professor. He has been an Associate Editor of the IEEE Trans. Image Processing (2010-) and an Editor of the Journal of Communications and Networks (JCN) (2009-), and the Chair of the IEEE P3333.1 Quality Assessment Working Group (2011-). He served as the Technical Committee of the IEEE IVMSP (2014-), the General Chair of the 2013 IEEE IVMSP workshop, and a guest editor of IEEE Trans. Image Processing 2013. He has received a 2012 special service award from IEEE Broadcast Technology Society and 2013 special service award from IEEE Signal Processing Society. His research interests include image/video quality assessments, medical image processing, cloud computing, wireless multimedia communications and wireless networks. </p>
        </div>
      </div> <!-- container -->
    </section>
    <!-- End CONTACT -->

    <!-- FOOTER begings -->
    <footer id="footer">    
      <div class="footer-widgets-wrap">
        <div class="container text-center">    
          <div class="row">
            <div class="col-sm-4 col-md-4">
              <div class="footer-content">
                <h4>KEEP IN TOUCH</h4>
                <div class="footer-socials">
                  <a href="#"><i class="fa fa-facebook"></i></a>
                  <a href="#"><i class="fa fa-google-plus"></i></a>
                  <a href="#"><i class="fa fa-twitter"></i></a>
                  <a href="#"><i class="fa fa-pinterest"></i></a>
                </div>
              </div> <!-- end footer-content -->
            </div> <!-- end col-sm-4 -->
            <div class="col-sm-4 col-md-4">
              <div class="footer-content">
                <h4>ADDRESS</h4>
                <p>C703, Engineering Hall C,<br>
                  50 Yonsei-ro, Seodaemun-gu,<br>
                  Seoul, Korea</p>
                <p>02-2123-7734<br>
                <a href="http://insight.yonsei.ac.kr/gnuboard/">http://insight.yonsei.ac.kr/gnuboard/</a></p>
              </div> <!-- end footer-content -->
            </div> <!-- end col-sm-4 -->
            <div class="col-sm-4 col-md-4">
              <div class="footer-content">
                <h4>SUPPORT</h4>
                <p>You need support? Visit our support forum and open tickets for you questions.</p>
                <p><button type="button" class="btn btn-custom-sm">forum</button></p>
              </div>  <!-- end footer-content -->   
            </div> <!-- end col-sm-4 -->
          </div> <!-- end row -->
        </div> <!-- container -->
      </div>
      <div class="footer-bottom text-center"> <!-- Footer-copyright -->
        <p>Â© insight.yonsei.ac.kr All rights reserved.</p>
      </div>
    </footer>
    <!-- End footer begings -->
    <!-- Scroll top -->
    <a href="#" class="back-to-top"> <i class="fa fa-chevron-up"> </i> </a>


    <!-- Style switcher -->
<!--    <div id="style-switcher" style="left: 0px;">-->
<!--        <div>-->
<!--            <h3>Select your color</h3>-->
<!--            <ul class="pattern">-->
<!--                <li><a class="color1" href="#"></a></li>-->
<!--                <li><a class="color2" href="#"></a></li>-->
<!--                <li><a class="color3" href="#"></a></li>-->
<!--                <li><a class="color4" href="#"></a></li>-->
<!--                <li><a class="color5" href="#"></a></li>-->
<!--                <li><a class="color6" href="#"></a></li>-->
<!--                <li><a class="color7" href="#"></a></li>-->
<!--                <li><a class="color8" href="#"></a></li>-->
<!--                <li><a class="color9" href="#"></a></li>-->
<!--                <li><a class="color10" href="#"></a></li>-->
<!--                <li><a class="color11" href="#"></a></li>-->
<!--                <li><a class="color12" href="#"></a></li>-->
<!--            </ul>-->
<!--        </div>      -->
<!--        <div class="bottom">-->
<!--            <a href="#" class="settings"><i class="fa fa-refresh fa-spin"></i></a>-->
<!--        </div>-->
<!--    </div>-->
    <!-- end Style switcher --> 


    <!-- JavaScript
     ================================================== -->
     <!-- Placed at the end of the document so the pages load faster -->
     <!-- initialize jQuery Library -->
     <script src="js/jquery.min.js"></script>
     <!-- jquery easing -->
     <script src="js/jquery.easing.min.js"></script>
     <!-- Bootstrap -->
     <script src="js/bootstrap.min.js"></script>
     <!-- modal-effect -->
     <script src="js/classie.js"></script>
     <script src="js/modalEffects.js"></script>
     <!-- Counter-up -->
     <script src="js/waypoints.min.js" type="text/javascript"></script>
     <script src="js/jquery.counterup.min.js" type="text/javascript"></script>
     <!-- SmoothScroll -->
     <script src="js/SmoothScroll.js"></script>
     <!-- Parallax -->
     <script src="js/jquery.stellar.min.js"></script>
     <!-- Jquery-Nav -->
     <script src="js/jquery.nav.js"></script>
     <!-- Owl carousel -->                                                      
     <script type="text/javascript" src="js/owl.carousel.min.js"></script>
     <!-- App JS -->
     <script src="js/app.js"></script>

     <!-- Switcher script for demo only -->
    <script type="text/javascript" src="js/switcher.js"></script>


  </body>
</html>
